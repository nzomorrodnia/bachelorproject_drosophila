{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nzomorrodnia/bachelorproject_drosophila/blob/main/IDS2023_Assignment5_Exercise56_nina.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# IDS Assignment 5 â€“ Computer Vision\n",
        "\n",
        "To work in this Colab notebook, first save a copy of it via \"File\" -> \"Save a copy in Drive\" in the top-left menu bar.\n"
      ],
      "metadata": {
        "id": "qL2_31R70NN0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Install all missing packages that we need an download our custom FashionMNIST data\n",
        "\n",
        "The data files will be available locally in your Colab runtime. You can find them through the files menu on the left."
      ],
      "metadata": {
        "id": "tBBfHMPW0ZQ4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install packages\n",
        "!pip install torchmetrics gdown\n",
        "\n",
        "# Download training, validation, and test splits\n",
        "!gdown https://drive.google.com/uc?id=1zYfBlExr_LK-Ld8rmxCTqRU5RAOUVVfh\n",
        "!gdown https://drive.google.com/uc?id=1PJa_I3qG0P5whuARV_Se1_YUvHzR469R\n",
        "!gdown https://drive.google.com/uc?id=1pC8-ummMGy1dPhHGPuNsms5_I7HpWgv2"
      ],
      "metadata": {
        "id": "OxY0aSy-6hGc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Import classes and functions we will be using"
      ],
      "metadata": {
        "id": "Ec72Ga6812RP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T9VpHD-DgtpQ"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "import os\n",
        "import random\n",
        "from typing import Any, Callable, Optional, Tuple\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "from torch.optim import SGD\n",
        "from torch.optim.lr_scheduler import LinearLR\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.datasets import VisionDataset\n",
        "from torchvision.transforms import Compose, Lambda, ToTensor\n",
        "from torchvision.models.resnet import ResNet, BasicBlock\n",
        "from torchmetrics.functional.classification import multiclass_confusion_matrix"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Check which PyTorch version we are running and confirm that we are in a GPU runtime.\n",
        "If this output shows that you are not in a GPU runtime, go to \"Runtime\" in the top-left menu bar -> \"Change runtime type\" -> set \"Hardware Accelerator: GPU\"."
      ],
      "metadata": {
        "id": "f5X2STV32RqW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Running PyTorch version: {torch.__version__}\")\n",
        "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
        "!nvidia-smi"
      ],
      "metadata": {
        "id": "mPccgagdC5hU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. Make things (more) reproducible by setting random seeds\n",
        "\n",
        "See here for details: https://pytorch.org/docs/stable/notes/randomness.html"
      ],
      "metadata": {
        "id": "48pQqaEu2rl_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "seed = 42\n",
        "random.seed(seed)\n",
        "np.random.seed(seed)\n",
        "torch.manual_seed(seed)\n",
        "torch.cuda.manual_seed_all(seed)"
      ],
      "metadata": {
        "id": "nl_WgwsJykDK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5. Define our custom IDS FashionMNIST PyTorch dataset\n",
        "\n",
        "Our model inherits, i.e. is a specific kind of, `VisionDataset` in torchvision.\\\n",
        "This means it has all features defined in `VisionDataset`, unless they are explicitly overridden here, \\\n",
        "plus any additional functionality that may be defined below. You can read more about `VisionDataset` here: https://pytorch.org/vision/main/generated/torchvision.datasets.VisionDataset.html."
      ],
      "metadata": {
        "id": "d9FscidJ266u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class IDSFashionMnistDataset(VisionDataset):\n",
        "    \"\"\"\n",
        "    FashionMNIST dataset for the IDS course which loads custom data files from disk\n",
        "    \"\"\"\n",
        "\n",
        "    classes = [\n",
        "        \"T-shirt/top\", \"Trouser\", \"Pullover\", \"Dress\", \"Coat\",\n",
        "        \"Sandal\", \"Shirt\", \"Sneaker\", \"Bag\", \"Ankle boot\"\n",
        "    ]\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        root: str,\n",
        "        split: str = \"training\",\n",
        "        transform: Optional[Callable] = None,\n",
        "        target_transform: Optional[Callable] = None,\n",
        "    ) -> None:\n",
        "        super().__init__(root, transform=transform, target_transform=target_transform)\n",
        "\n",
        "        if not split in [\"training\", \"validation\", \"test\"]:\n",
        "            raise ValueError(\"Split should be 'training', 'validation', or 'test'.\")\n",
        "\n",
        "        self.split = split\n",
        "        self.root = root\n",
        "\n",
        "        self.data, self.targets = self._load_data()\n",
        "\n",
        "    def _load_data(self):\n",
        "        data = torch.load(os.path.join(self.root, f\"fashion_mnist_{self.split}.pt\"))\n",
        "        images = data[:, :-1].reshape(-1, 28, 28)  # 28x28 resolution\n",
        "        labels = data[:, -1]\n",
        "        return images, labels\n",
        "\n",
        "    def __getitem__(self, index: int) -> Tuple[Any, Any]:\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            index (int): Index\n",
        "\n",
        "        Returns:\n",
        "            tuple: (image, target) where target is index of the target class.\n",
        "        \"\"\"\n",
        "        img, target = self.data[index], int(self.targets[index])\n",
        "\n",
        "        # doing this so that it is consistent with all other datasets\n",
        "        # to return a PIL Image\n",
        "        img = Image.fromarray(img.numpy(), mode=\"L\")\n",
        "\n",
        "        if self.transform is not None:\n",
        "            img = self.transform(img)\n",
        "\n",
        "        if self.target_transform is not None:\n",
        "            target = self.target_transform(target)\n",
        "\n",
        "        return img, target\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)"
      ],
      "metadata": {
        "id": "rQRFvmlVrXyb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6. Define our custom ResNet-18 model for FashionMNIST\n",
        "The original ResNet-18 uses 3-channel (RGB) inputs and has 1000 output classes based on ImageNet-1K.\n",
        "\n",
        "https://pytorch.org/vision/main/models/generated/torchvision.models.resnet18.html\n",
        "\n",
        "We instead use single-channel inputs (Grayscale) and 10 output classes according to FashionMNIST."
      ],
      "metadata": {
        "id": "bYZm4f-G3bJb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class FashionMnistResNet18(ResNet):\n",
        "    \"\"\"\n",
        "    Custom ResNet-18 model which uses 1 input channel (grayscale) and has 10 output classes\n",
        "    \"\"\"\n",
        "    def __init__(self):\n",
        "        super().__init__(BasicBlock, [2,2,2,2,2], num_classes=10)\n",
        "        self.conv1 = nn.Conv2d(1, 64,\n",
        "          kernel_size=(7, 7),\n",
        "          stride=(2, 2),\n",
        "          padding=(3, 3),\n",
        "          bias=False\n",
        "        )"
      ],
      "metadata": {
        "id": "dOKZ40RW31jy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 7. Load our custom FashionMNIST data\n",
        "\n",
        "Here, we load our data using the `IDSFashionMnistDataset` class defined above. We also make use of the functionality in torchvision's `VisionDataset`, which `IDSFashionMnistDataset` inherits from, to set the transformations we want to apply when retrieving examples from our dataset. We use the `transform` keyword argument for this and compose our transformations using torchvision's `Compose` (https://pytorch.org/vision/main/generated/torchvision.transforms.Compose.html). In our base setting, the only transformation we apply is `ToTensor`, which converts our `PIL.Image` inputs into PyTorch tensors."
      ],
      "metadata": {
        "id": "JtzPBiiq4RnD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create base transformation for our dataset\n",
        "# TODO: how can these be modified to randomly flip examples?\n",
        "base_transform = Compose([\n",
        "    ToTensor(),\n",
        "])\n",
        "\n",
        "# Load datasets\n",
        "train_dataset = IDSFashionMnistDataset(\".\", \"training\", transform=base_transform)\n",
        "validation_dataset = IDSFashionMnistDataset(\".\", \"validation\", transform=base_transform)\n",
        "test_dataset = IDSFashionMnistDataset(\".\", \"test\", transform=base_transform)\n",
        "\n",
        "# Check the sizes of our datasets\n",
        "print(f\"Training dataset length = {len(train_dataset)}\")\n",
        "print(f\"Validation dataset length = {len(validation_dataset)}\")\n",
        "print(f\"Test dataset length = {len(test_dataset)}\")"
      ],
      "metadata": {
        "id": "fLWIwbs1lKtT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 8. Implement our evaluation function and training loop\n",
        "\n",
        "Below, we provide some rudimentary functionality for training and evaluation,\\\n",
        "as well as metric storing and logging, for our experiments."
      ],
      "metadata": {
        "id": "HeQRTMvk5i52"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def log_metrics(metrics: dict, step: Optional[int] = None):\n",
        "    \"\"\"\n",
        "    Log metrics stored in a dictionary\n",
        "    \"\"\"\n",
        "\n",
        "    # During training, it can be useful to also log the current step\n",
        "    if step is not None:\n",
        "        print(f\"\\nMetrics step {step}:\")\n",
        "\n",
        "    for k, v in metrics.items():\n",
        "        # We ignore the confusion matrix when logging metrics\n",
        "        if not k.endswith(\"conf_matrix\"):\n",
        "            print(f\"  {k}: {v}\")\n",
        "\n",
        "def evaluate(model, eval_dataloader, prefix=\"eval\"):\n",
        "    \"\"\"\n",
        "    Evaluation function that computes the loss, accuracy, and confusion matrix for the dataset\n",
        "    passed via the `eval_dataloader` argument\n",
        "    \"\"\"\n",
        "\n",
        "    # Define loss function\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    # Move model to GPU\n",
        "    model.cuda()\n",
        "\n",
        "    # Set model to evaluation mode (e.g. to disable dropout)\n",
        "    model.eval()\n",
        "\n",
        "    eval_loss = 0\n",
        "    y_pred = None\n",
        "    y_true = None\n",
        "    num_classes = None\n",
        "\n",
        "    for batch_idx, batch in enumerate(tqdm(eval_dataloader, desc=f\"Evaluating\")):\n",
        "        # Loop over batches in dataloader\n",
        "\n",
        "        # Move batch to GPU\n",
        "        inputs, labels = batch\n",
        "        inputs = inputs.cuda()\n",
        "        labels = labels.cuda()\n",
        "\n",
        "        # Use no_grad mode to disable gradient computation\n",
        "        with torch.no_grad():\n",
        "            # Get model outputs\n",
        "            outputs = model(inputs)\n",
        "\n",
        "        # Compute loss\n",
        "        loss = criterion(outputs, labels)\n",
        "        eval_loss += loss.detach().cpu().item()\n",
        "\n",
        "        if num_classes is None:\n",
        "            num_classes = len(outputs[0])\n",
        "\n",
        "        # Get class predictions\n",
        "        preds = torch.argmax(outputs, dim=-1)\n",
        "\n",
        "        # Accumulate predictions and true classes over batches\n",
        "        y_pred = torch.cat([y_pred, preds]) if y_pred is not None else preds\n",
        "        y_true = torch.cat([y_true, labels]) if y_true is not None else labels\n",
        "\n",
        "\n",
        "    # Move predictions and true classes back to CPU\n",
        "    y_pred = y_pred.detach().cpu()\n",
        "    y_true = y_true.detach().cpu()\n",
        "\n",
        "    # Compute metrics\n",
        "    eval_loss /= len(eval_dataloader)\n",
        "    eval_acc = (y_pred == y_true).sum() / len(y_true)\n",
        "    eval_conf_matrix = multiclass_confusion_matrix(\n",
        "        y_pred, y_true, num_classes=num_classes\n",
        "    )\n",
        "\n",
        "    # Store metrics in a dictionary\n",
        "    metrics = {\n",
        "        f\"{prefix}_loss\": eval_loss,\n",
        "        f\"{prefix}_accuracy\": eval_acc.item(),\n",
        "        f\"{prefix}_conf_matrix\": eval_conf_matrix.numpy()\n",
        "    }\n",
        "\n",
        "    return metrics\n",
        "\n",
        "\n",
        "def save_best_model(model: nn.Module):\n",
        "  \"\"\"\n",
        "  Simple function that saves the weights of the specified model to disk.\n",
        "  We use this to keep track of the best model (based on validation loss).\n",
        "  \"\"\"\n",
        "  output_path = \"best_model.pt\"\n",
        "  torch.save(model.state_dict(), output_path)\n",
        "  print(f\"Saved new best model to {output_path}\\n\")\n",
        "\n",
        "\n",
        "def load_best_model(model: nn.Module, model_path: str = \"best_model.pt\"):\n",
        "  \"\"\"\n",
        "  Simple function that loads model weights stored at `model_path` into the\n",
        "  passed model of type `nn.Module`. We use this to load our best model checkpoint.\n",
        "  \"\"\"\n",
        "  model.load_state_dict(torch.load(model_path))\n",
        "  model.eval()\n",
        "  print(f\"Loaded best {model.__class__.__name__} model from {model_path}\\n\")\n",
        "  return model\n",
        "\n",
        "\n",
        "def train(\n",
        "  model: nn.Module,\n",
        "  train_dataloader: DataLoader,\n",
        "  eval_dataloader: DataLoader,\n",
        "  num_epochs: int = 20,\n",
        "  lr: float = 0.1,\n",
        "  eval_steps: int = 100\n",
        "):\n",
        "    \"\"\"\n",
        "    Training loop\n",
        "    \"\"\"\n",
        "\n",
        "    # Create SGD optimizer with specified learning rate and fixed momentum\n",
        "    optimizer = SGD(model.parameters(), lr=lr, momentum=0.9)\n",
        "\n",
        "    # Create linear learning rate decay schedule\n",
        "    scheduler = LinearLR(\n",
        "        optimizer,\n",
        "        start_factor=1.0,\n",
        "        end_factor=1e-6,\n",
        "        total_iters=len(train_dataloader) * num_epochs\n",
        "    )\n",
        "\n",
        "    # Define loss function\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    # Move model to GPU\n",
        "    model.cuda()\n",
        "\n",
        "    total_loss = 0\n",
        "    total_eval_loss = 0\n",
        "    global_step = 0\n",
        "    global_eval_step = 0\n",
        "    best_eval_loss = float(\"inf\")\n",
        "\n",
        "    # Store our initial model\n",
        "    save_best_model(model)\n",
        "\n",
        "    # Create dictionary to store metrics throughout training\n",
        "    metrics_dict = {}\n",
        "\n",
        "    print(\"Starting model training\")\n",
        "\n",
        "    for epoch_idx in range(num_epochs):\n",
        "        # Epoch loop (one epoch is one pass over the full training dataset)\n",
        "\n",
        "        for batch_idx, batch in enumerate(tqdm(train_dataloader, desc=f\"Epoch {epoch_idx+1}\")):\n",
        "            # Loop over batches in training dataset\n",
        "\n",
        "            # Set model to training mode\n",
        "            model.train()\n",
        "\n",
        "            global_step += 1\n",
        "\n",
        "            # Move batch to GPU\n",
        "            inputs, labels = batch\n",
        "            inputs = inputs.cuda()\n",
        "            labels = labels.cuda()\n",
        "\n",
        "            # Get model outputs\n",
        "            outputs = model(inputs)\n",
        "\n",
        "            # Compute loss\n",
        "            loss = criterion(outputs, labels)\n",
        "            total_loss += loss.detach().cpu().item()\n",
        "\n",
        "            # Evaluation loop\n",
        "            if global_step % eval_steps == 0:\n",
        "                global_eval_step += 1\n",
        "                metrics = {\n",
        "                    \"mean_train_loss\": total_loss / global_step,\n",
        "                    \"learning_rate\": scheduler.get_last_lr()[0]\n",
        "                }\n",
        "\n",
        "                # Evaluate on validation and training datasets\n",
        "                metrics.update(evaluate(model, eval_dataloader, prefix=\"eval\"))\n",
        "                metrics.update(evaluate(model, train_dataloader, prefix=\"train\"))\n",
        "\n",
        "                # Update and log metrics\n",
        "                total_eval_loss += metrics[\"eval_loss\"]\n",
        "                metrics[\"mean_eval_loss\"] = total_eval_loss / global_eval_step\n",
        "                log_metrics(metrics, step=global_step)\n",
        "                metrics_dict[global_step] = metrics\n",
        "\n",
        "                # Check if our validation loss has decreased, and if so,\n",
        "                # update our best model checkpoint\n",
        "                if metrics[\"eval_loss\"] <= best_eval_loss:\n",
        "                  best_eval_loss = metrics[\"eval_loss\"]\n",
        "                  save_best_model(model)\n",
        "\n",
        "            # Compute gradients\n",
        "            loss.backward()\n",
        "\n",
        "            # Perform update step\n",
        "            optimizer.step()\n",
        "\n",
        "            # Reduce learning rate for stability\n",
        "            scheduler.step()\n",
        "\n",
        "            # Set gradients to zero\n",
        "            model.zero_grad()\n",
        "\n",
        "    return metrics_dict"
      ],
      "metadata": {
        "id": "2mqMKk35ip9f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 9. Define hyperparameters, create dataloaders, instantiate model, and run training/evaluation procedure\n",
        "\n",
        "Here, we set our hyper-parameters for the dataloader (batch size) and the training loop \\\n",
        "(number of epochs, learning rate, and evaluation interval in steps).\n",
        "\n",
        "We only use very basic data loading functionality. More information on available features can be found here https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader."
      ],
      "metadata": {
        "id": "v2h72BWltFaY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: set your hyperparameters\n",
        "bs = None\n",
        "num_epochs = None\n",
        "lr = None\n",
        "eval_steps = None\n",
        "\n",
        "# Create dataloaders\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=bs, shuffle=True)\n",
        "validation_dataloader = DataLoader(validation_dataset, batch_size=bs, shuffle=False)\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=bs, shuffle=False)\n",
        "\n",
        "# Instantiate a new model\n",
        "model = FashionMnistResNet18()\n",
        "\n",
        "# Train model and save training and evaluation metrics\n",
        "metrics_dict = train(\n",
        "    model, train_dataloader, validation_dataloader, num_epochs=num_epochs, lr=lr, eval_steps=eval_steps\n",
        ")"
      ],
      "metadata": {
        "id": "EBGaR6FmsWtF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 10. Load our saved best model checkpoint\n",
        "\n",
        "We can make use of the `load_best_model` function defined above to quickly load \\\n",
        "the best model checkpoint for further evaluation.\n",
        "\n",
        "You can find more information on saving and loading model weights at\n",
        "\n",
        "https://pytorch.org/tutorials/beginner/saving_loading_models.html."
      ],
      "metadata": {
        "id": "C27zjwzquLGx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "best_model = load_best_model(FashionMnistResNet18())"
      ],
      "metadata": {
        "id": "w8AolrjruF4I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 11. Evaluate your best model and visualize the confusion matrix\n",
        "\n",
        "TODO: You should implement this yourself using the functions defined above."
      ],
      "metadata": {
        "id": "t4DlELCbvybc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO"
      ],
      "metadata": {
        "id": "WKHN3rh6v-mU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 12. Plot your loss curves\n",
        "\n",
        "TODO: You should implement this yourself. Use the `metrics_dict` returned by the training loop."
      ],
      "metadata": {
        "id": "VpGn2mqkv9H0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO"
      ],
      "metadata": {
        "id": "DJeeESOUwzVz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 12. Plot your accuracy curves\n",
        "\n",
        "TODO: You should implement this yourself. Use the `metrics_dict` returned by the training loop."
      ],
      "metadata": {
        "id": "T9B2Pp3ywDEf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO"
      ],
      "metadata": {
        "id": "5GkdPLh8w3oi"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}